from __future__ import annotations

import os
from dotenv import load_dotenv

import json
import base64 
import logging
from typing import Dict, Any, Optional,List,Union, Iterable
from pydantic import BaseModel, Field, ValidationError

logger = logging.getLogger(__name__)

load_dotenv()  # Load environment variables from .env file

AI_PIPE_TOKEN = os.getenv("AI_PIPE_TOKEN")

class GeneratedFiles(BaseModel):
    """Schema for the files generated by the LLM.
    This class definition GeneratedFiles is a Pydantic model that defines
    a schema for the files generated by the LLM (Language Model).
    It has a single field named files, which is a dictionary mapping filenames
    (e.g., 'index.html', 'script.js') to their complete content as a string.
    The Field decorator is used to provide a description for the field."""
    # Reverting to the dictionary structure for simplicity
    files: Dict[str, str] = Field(
        description="A dictionary mapping filenames (e.g., 'index.html', 'script.js') to their complete content as a string."
    )


class GenerateCodeLLM:
    def __init__(self, model: Optional[str] = "openai/gpt-4.1-nano"):
        if not AI_PIPE_TOKEN:
            raise ValueError("AI_PIPE_TOKEN environment variable is required for LLM calls.")
        
        self.model = model
        self.token = AI_PIPE_TOKEN
        
        
    def _process_attachments(self,attachments: Union[str, Dict[str, Any], Iterable[Union[str, Dict[str, Any]]]]) -> str:
        """Accepts a single attachment or an iterable of attachments.

        Each attachment may be:
        - a data URI string (data:...;base64,AAA...)
        - a plain URL string (http(s)://... or file://...)
        - a dict with keys 'url' and optional 'name'

        The function will decode data: URIs (base64) for non-image types and return a formatted
        summary. For image data URIs it will NOT decode â€” the data URI is preserved as an attachment.
        For non-data URLs it will include the URL as a reference.
        No network requests are made.
        """
        # normalize to a list
        items: List[Union[str, Dict[str, Any]]] = []
        if isinstance(attachments, (str, dict)):
            items = [attachments]
        else:
            try:
                items = list(attachments)
            except TypeError:
                # fallback: treat as single string
                items = [str(attachments)]

        processed_data: List[str] = []

        for idx, attachment in enumerate(items):
            # normalize dict form
            if isinstance(attachment, dict):
                url = attachment.get("url", "")
                name = attachment.get("name") or attachment.get("filename") or f"attachment_{idx}"
            else:
                url = str(attachment)
                name = f"attachment_{idx}"

            if not url:
                print(f"Warning: empty url for {name} (index {idx})")
                continue

            if url.startswith("data:"):
                # data:[<mediatype>][;base64],<data>
                try:
                    header, encoded_data = url.split(',', 1)
                except ValueError:
                    print(f"Error: Invalid data URI format for {name}")
                    continue

                # get media type (may be empty)
                media_type = header[5:].split(';')[0].lower() if len(header) > 5 else ""

                # If it's an image, do not decode: preserve the data URI as an attachment reference.
                if media_type.startswith("image/"):
                    processed_data.append(
                        f"## Attached File: {name}\n"
                        f"Content-Type: {media_type or 'image/*'}\n"
                        f"Note: image data URI preserved as attachment (not decoded) and you can use it directly\n"
                        f"Data-URI: {url}\n"
                    )
                    continue

                # detect base64 marker for non-image types
                is_base64 = header.endswith(";base64") or ";base64;" in header

                if is_base64:
                    try:
                        # base64 may include padding/newlines
                        decoded_bytes = base64.b64decode(encoded_data)
                        # try utf-8, fallback to latin-1 to avoid losing bytes
                        try:
                            decoded_content = decoded_bytes.decode('utf-8')
                        except UnicodeDecodeError:
                            decoded_content = decoded_bytes.decode('latin-1')

                        sample_content = decoded_content[:1000]
                        processed_data.append(
                            f"## Attached File: {name}\n"
                            f"Content-Type: {media_type or header[5:]}\n"
                            f"--- Content Sample ---\n"
                            f"{sample_content}\n"
                            f"----------------------\n"
                        )
                    except Exception as e:
                        print(f"Error decoding base64 attachment {name}: {e}")
                else:
                    # data URI but not base64 - it's probably URL-encoded
                    try:
                        import urllib.parse

                        decoded = urllib.parse.unquote(encoded_data)
                        sample = decoded[:1000]
                        processed_data.append(
                            f"## Attached File: {name}\n"
                            f"Content-Type: {media_type or header[5:]}\n"
                            f"--- Content Sample (URL-decoded) ---\n"
                            f"{sample}\n"
                            f"----------------------\n"
                        )
                    except Exception as e:
                        print(f"Error decoding URL-encoded data URI for {name}: {e}")

            else:
                # Not a data: URI. We won't fetch over network; just include reference.
                processed_data.append(
                    f"## Attached File: {name}\n"
                    f"URL: {url}\n"
                )

        return "\n".join(processed_data)
    
    def generate_app_files(self, task_request: dict) -> Dict[str, str]:
        """Generates code files based on the task and returns them as a dictionary."""
        
        # 1. Prepare Data and Prompts
        attachments_context = self._process_attachments(task_request.get("attachments", []))
        brief = task_request.get("brief", "No detailed brief provided.")
        checks = task_request.get("checks", [])
        print(f"Generating files for brief: {brief} with checks: {checks}")
        # System Prompt enforces the role and output constraints (reverted to dictionary instruction)
        # print(attachments_context)

        user_prompt_text = (
            f"Generate all necessary files (at least index.html) to complete the following task:\n\n"
            f"**TASK BRIEF:** {brief}\n\n"
            f"**VERIFICATION CHECKS (for context):** {checks}\n\n"
            f"**ATTACHED DATA:**\n{attachments_context}\n\n"
            f"Ensure the generated code successfully meets the brief and is fully contained in the 'files' dictionary."
        )

        generated_files = self._call_llm(user_prompt_text, model=self.model)
        return generated_files

    def _call_llm(self,prompt: str, model: Optional[str] = "openai/gpt-4.1-nano") -> str:
        """Call an OpenAI-compatible chat completion using a proxy server AI PIPE and return text content.

        Requires AI_PIPE_TOKEN in environment.
        """
        token = os.getenv("AI_PIPE_TOKEN")
        if not token:
            raise ValueError("AI_PIPE_TOKEN environment variable is required for LLM calls.")
        import requests
        
        headers = {
        "Authorization": f"Bearer {self.token}",
        "Content-Type": "application/json"
        }
        
        url = "https://aipipe.org/openrouter/v1/chat/completions"
        
        system_prompt = (
                "You are an expert web developer specializing in generating clean, single-page "
                "web applications for simple tasks. Your output MUST be a single, valid JSON object "
                "that strictly adheres to the provided schema. The JSON object MUST contain a "
                "'files' dictionary where keys are the complete filenames (e.g., 'index.html', 'script.js') "
                "and values are the full content of those files as a string. "
                
                # --- ADDED REQUIREMENTS FOR EVALUATION COMPLIANCE ---
                "In addition to the main application files, you MUST ALWAYS include the following two files: "
                "1. **README.md**: A detailed README file specific to the application, describing its features and how to run it. "
                "2. **LICENSE**: The full and complete text of the MIT License. "
                
                # --- RETAINED STRICTNESS ---
                "\nDO NOT include any explanation, markdown formatting outside of the JSON block, or preamble."
            )
        
        payload = {
            "model": model,
            "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt},
                ]
        }
        print(prompt)
        print("Sending request to LLM...")
        try:
            response = requests.post(url, headers=headers, json=payload)
        except Exception as e:
            raise ValueError(f"LLM API call failed: {e}")

        print(f"LLM response status: {response.status_code}")
        if response.status_code != 200:
            raise ValueError(f"LLM API call failed: {response.status_code} {response.text}")

        # The LLM may return the JSON object as a string in message.content. Parse if needed.
        try:
            message_content = response.json()['choices'][0]['message']['content']
        except (ValueError, KeyError) as e:
            # ValueError from response.json() when body isn't JSON; KeyError if structure unexpected
            raise RuntimeError(f"Failed to parse LLM response JSON: {e}")

        # If the content is a JSON string, decode it into a Python dict first.
        if isinstance(message_content, str):
            try:
                parsed = json.loads(message_content)
            except json.JSONDecodeError:
                # Content wasn't valid JSON
                raise RuntimeError("LLM returned a non-JSON string in message.content")
        else:
            parsed = message_content

        # Validate against the GeneratedFiles schema and return the files dict
        try:
            validated_output = GeneratedFiles.model_validate(parsed)
        except ValidationError as e:
            raise RuntimeError(f"LLM returned invalid JSON structure or schema mismatch: {e}")
        
        return validated_output.files



    
    

